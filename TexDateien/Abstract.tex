\chapter*{Abstract} 
In dieser Arbeit wird ein Webcrawler entwickelt, welcher dafür verwendet werden kann, eine Vielzahl von Webseiten mit einem Browser zu besuchen. Dabei wird vor allem auf verschiedene Strategien beim Webcrawling eingegangen und die beste Architektur ermittelt. Zusätzlich wird die Implementierung der wichtigsten Komponenten beschrieben.\\
Als Anwendungsfalls dient die automatische Erkennung von DOM basierten Cross-Site Scripting Schwachstellen. Dafür wird ein bereits vorhandener Analyseworkerflow mit dem Webcrawler verbunden. Das Ergebnis sind 126 konkrete Schwachstellen, die auf teilweise sehr bekannten Webseiten gefunden wurden.
